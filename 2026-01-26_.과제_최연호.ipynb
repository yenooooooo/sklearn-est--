{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef388e19",
   "metadata": {},
   "source": [
    "**CES 2026에서 관측되는 Physical AI의 “현황(What’s real now)”**을 먼저 정리하고, **CES 2025 대비 큰 틀의 변화**, 마지막으로 **2027년 전개 전망(가정 포함)** 순서로 구성했습니다. \n",
    "\n",
    "---\n",
    "\n",
    "## 1) CES 2026에서 본 Physical AI “현황”\n",
    "\n",
    "### 1.1. 키워드의 의미가 “로봇 데모”가 아니라 “시스템 아키텍처”로 정착\n",
    "\n",
    "CES(CTA) 자체가 2026년 로보틱스 트렌드를 **“physical AI”**로 명시하면서, 이를 **분석형 AI(의사결정/최적화) + 생성형 AI(시뮬레이션 기반 학습)**의 결합으로 설명합니다. 즉 “물리 세계에서 결과를 만들어내는 AI”를 전시의 중심 프레임으로 올려놓은 상태입니다. ([CES][1])\n",
    "\n",
    "여기서 관측되는 공통분모는 다음 4가지입니다.\n",
    "\n",
    "* **(1) 데이터 문제를 ‘실세계 수집’만으로 풀지 않는다 → 합성 데이터/시뮬 중심으로 전환**\n",
    "* **(2) 모델만이 아니라 “훈련–평가–배포” 파이프라인을 함께 제공**\n",
    "* **(3) 지연시간/비용 때문에 “엣지 실행(온디바이스)” 비중이 커짐**\n",
    "* **(4) 파트너 로봇/산업 적용 사례가 “테마”가 아니라 “제품 로드맵”으로 제시됨**\n",
    "\n",
    "---\n",
    "\n",
    "### 1.2. NVIDIA가 제시한 “Physical AI 스택”이 CES 2026의 기준점 역할\n",
    "\n",
    "CES 2026에서 Physical AI 논의를 구조화한 대표 사례가 NVIDIA 발표입니다. 핵심은 “로봇을 만들겠다”가 아니라, **로봇/자율기계가 대규모로 만들어질 수 있는 빌딩블록(모델·데이터·평가·엣지 컴퓨팅·워크플로)**을 공개/확장했다는 점입니다. ([NVIDIA Newsroom][2])\n",
    "\n",
    "구체 구성요소(현황)는 다음처럼 정리됩니다.\n",
    "\n",
    "#### A) 오픈(또는 공개) 모델/월드모델 계열을 전면 배치\n",
    "\n",
    "* Cosmos 계열 “월드(환경) 모델”을 물리 AI 개발/검증 가속의 중심으로 두고, 합성 데이터/세계 생성/추론을 강조합니다. ([NVIDIA Blog][3])\n",
    "\n",
    "#### B) “정책(Policy) 평가”가 제품 단위로 올라옴\n",
    "\n",
    "* 일반화 로봇 정책을 **시뮬레이션에서 평가**하기 위한 Isaac Lab-Arena 같은 도구가 언급됩니다(단순 데모를 넘어 “평가/검증”을 체계화). ([NVIDIA Developer Forums][4])\n",
    "\n",
    "#### C) 엣지 실행을 위한 하드웨어/런타임 메시지가 강해짐\n",
    "\n",
    "* Jetson T4000 같은 엣지 모듈을 “실시간 로봇/온디바이스 AI”의 기반으로 전면에 둡니다. ([NVIDIA Newsroom][2])\n",
    "* CES 2026 보도에서도 NVIDIA의 “physical AI”를 **시뮬레이션에서 학습 → 물리 하드웨어에 배치**하는 접근으로 요약합니다. ([Mastercard][5])\n",
    "\n",
    "#### D) 오픈소스 커뮤니티 연결(LeRobot 등)로 개발자 풀을 키우는 전략\n",
    "\n",
    "* Hugging Face 생태계(LeRobot)와의 결합을 통해 오픈소스 로보틱스 흐름을 “주류 개발경로”로 끌어오는 방향이 드러납니다. ([NVIDIA Newsroom][2])\n",
    "\n",
    "---\n",
    "\n",
    "### 1.3. “파트너 로봇”이 많아진 정도가 아니라, 산업별 적용 시나리오가 구체화\n",
    "\n",
    "CES 2026에서는 휴머노이드/산업로봇이 단순 쇼케이스를 넘어, **제조·물류·가정·헬스케어** 등으로 퍼지는 흐름이 공식 요약과 현장 리포트에서 반복됩니다. ([CES][1])\n",
    "\n",
    "대표적으로 현대차그룹/보스턴다이내믹스의 Atlas는 “공장 투입 시점/계획” 같은 서사가 함께 제시됩니다(예: 2028년 공장 투입 계획 등). ([Autoweek][6])\n",
    "또한 CES 현장 보도는 로봇/자율기계가 “AI 중심 전시”의 한가운데로 이동했다고 정리합니다. ([AP News][7])\n",
    "\n",
    "---\n",
    "\n",
    "### 1.4. 병목(현실 제약)도 “공개적으로” 다뤄지는 단계\n",
    "\n",
    "CES 2026의 Physical AI는 낙관만이 아니라, **신뢰성·안전·스케일·경제성**이 핵심 과제로 전면화됩니다. “데모를 넘어 운영 가능한가”가 질문이 되고 있고, 업계 관점 리포트에서도 이 지점을 짚습니다. ([aicas][8])\n",
    "또한 로봇을 물리 환경에 배치할수록 **데이터 부족/안전/망각(catastrophic forgetting)** 등 난제가 커진다는 지적도 병행됩니다. ([Financial Times][9])\n",
    "\n",
    "---\n",
    "\n",
    "## 2) CES 2025 대비 “큰 틀”에서 달라진 점\n",
    "\n",
    "### 2.1. 2025: “Physical AI 시대 선언 + 개발 패러다임 제시(시뮬/월드모델)”\n",
    "\n",
    "CES 2025에서 NVIDIA는 **Cosmos(월드 파운데이션 모델 플랫폼)**을 통해, 로봇/자율주행 개발의 핵심 문제(실세계 데이터·테스트 비용)를 **시뮬레이션/합성 데이터**로 푸는 프레임을 강하게 제시했습니다. ([NVIDIA Newsroom][10])\n",
    "\n",
    "### 2.2. 2026: “개념 → 시스템(모델·평가·엣지·워크플로) + 생태계 확장”\n",
    "\n",
    "2026에서는 같은 축이 “더 구체적인 제품 묶음”으로 내려옵니다.\n",
    "\n",
    "* **모델만이 아니라 평가/검증(시뮬레이션 Arena)까지 패키지화** ([NVIDIA Developer Forums][4])\n",
    "* **엣지 실행(온디바이스/저지연) 강조가 크게 상승** ([NVIDIA Newsroom][2])\n",
    "* **오픈소스 로보틱스(LeRobot 등)와의 연결을 통해 개발자 유입을 ‘경로’로 설계** ([NVIDIA Newsroom][2])\n",
    "* **로봇이 CES의 주변이 아니라 중심 카테고리로 공식 요약에 등장** ([CES][1])\n",
    "\n",
    "정리하면,\n",
    "\n",
    "* **CES 2025 = “Physical AI를 가능하게 하는 핵심 개념(월드모델/시뮬) 소개”**\n",
    "* **CES 2026 = “그 개념을 산업이 쓰도록 만드는 ‘시스템 아키텍처 + 생태계’ 전개”**\n",
    "\n",
    "---\n",
    "\n",
    "## 3) 2027년은 어떻게 흘러갈까 (전망)\n",
    "\n",
    "아래는 CES 2026에서 드러난 방향성을 기반으로 한 **합리적 시나리오(확정 아님)**입니다.\n",
    "\n",
    "### 3.1. “표준 스택” 경쟁이 심화: 로보틱스의 Android/Windows 모멘트\n",
    "\n",
    "CES 2026에서 보인 흐름은 개별 로봇 브랜드 경쟁이라기보다, **공통 스택(모델·시뮬·평가·런타임·배포)**을 누가 장악하느냐에 가깝습니다. 이 구도가 2027년에는 더 노골화될 가능성이 큽니다. (NVIDIA의 오픈 모델/툴, Arm의 Physical AI 조직 신설 등이 같은 방향) ([Reuters][11])\n",
    "\n",
    "### 3.2. “벤치마크/평가”가 구매/도입의 언어가 됨\n",
    "\n",
    "2026에 “정책 평가(Arena)”가 올라온 것은 신호입니다. 2027에는\n",
    "\n",
    "* 작업 성공률, 안전 지표, 회복(Recovery) 능력, 인간 협업 성능 등\n",
    "  **정량 평가가 도입 의사결정의 필수 문서**가 될 가능성이 높습니다. ([NVIDIA Developer Forums][4])\n",
    "\n",
    "### 3.3. 합성 데이터/시뮬 기반 학습이 “기본값”이 됨\n",
    "\n",
    "현실 데이터 수집의 병목은 구조적으로 해소가 어렵습니다. 2027에는\n",
    "\n",
    "* 합성 데이터 생성, 도메인 랜덤화, 시뮬→현실 전이(Sim2Real)\n",
    "  이 영역이 **로봇 개발 비용 구조를 좌우하는 핵심 공정**으로 굳어질 가능성이 큽니다. ([NVIDIA Newsroom][10])\n",
    "\n",
    "### 3.4. 엣지-클라우드 분업이 정리됨: “실시간은 엣지, 대규모 학습은 클라우드”\n",
    "\n",
    "지연시간/프라이버시/연결성 이슈 때문에, 2027에는\n",
    "\n",
    "* **온디바이스 추론(실시간 제어/안전)**\n",
    "* **클라우드 학습/시뮬레이션(대규모 업데이트)**\n",
    "  이 분업이 더 명확해질 전망입니다. (하드웨어 진화와 맞물림) ([NVIDIA Newsroom][2])\n",
    "\n",
    "### 3.5. “휴머노이드 붐”은 계속되지만, 승자는 ‘범용성’보다 ‘ROI가 나오는 작업’에서 먼저 결정\n",
    "\n",
    "2027에는 휴머노이드가 계속 주목을 받더라도, 실제 확산은\n",
    "\n",
    "* 물류 피킹/이송, 공장 내 반복 작업, 위험 작업 대체, 병원 보조 등\n",
    "  **ROI가 즉시 계산되는 업무 단위**에서 먼저 확정될 가능성이 큽니다. ([Financial Times][9])\n",
    "\n",
    "---\n",
    "\n",
    "* [AP News](https://apnews.com/article/a3e6e4e582ff83a4aa331d1791140369?utm_source=chatgpt.com)\n",
    "* [Reuters](https://www.reuters.com/business/autos-transportation/arm-launches-physical-ai-division-expand-robotics-market-2026-01-07/?utm_source=chatgpt.com)\n",
    "* [Autoweek](https://www.autoweek.com/news/a69927309/hyundai-future-is-robots/?utm_source=chatgpt.com)\n",
    "* [Financial Times](https://www.ft.com/content/3449e77c-721b-4fc9-8082-c584d8f74848?utm_source=chatgpt.com)\n",
    "* [Tom's Hardware](https://www.tomshardware.com/pc-components/gpus/nvidia-launches-vera-rubin-nvl72-ai-supercomputer-at-ces-promises-up-to-5x-greater-inference-performance-and-10x-lower-cost-per-token-than-blackwell-coming-2h-2026?utm_source=chatgpt.com)\n",
    "\n",
    "[1]: https://www.ces.tech/press-releases/ces-2026-the-future-is-here?utm_source=chatgpt.com \"CES 2026: The Future is Here\"\n",
    "[2]: https://nvidianews.nvidia.com/news/nvidia-releases-new-physical-ai-models-as-global-partners-unveil-next-generation-robots?utm_source=chatgpt.com \"NVIDIA Releases New Physical AI Models as Global ...\"\n",
    "[3]: https://blogs.nvidia.com/blog/open-models-data-tools-accelerate-ai/?utm_source=chatgpt.com \"NVIDIA Unveils New Open Models, Data and Tools to ...\"\n",
    "[4]: https://forums.developer.nvidia.com/t/nvidia-robotics-announcements-ces-2026/356606?utm_source=chatgpt.com \"NVIDIA Robotics Announcements - CES 2026\"\n",
    "[5]: https://www.mastercard.com/global/en/news-and-trends/stories/2026/ces-2026.html?utm_source=chatgpt.com \"CES 2026: AI takes center stage in chips, cars and robots\"\n",
    "[6]: https://www.autoweek.com/news/a69927309/hyundai-future-is-robots/?utm_source=chatgpt.com \"Hyundai Thinks the Next Mobility Revolution Isn't a Car\"\n",
    "[7]: https://apnews.com/article/a3e6e4e582ff83a4aa331d1791140369?utm_source=chatgpt.com \"The coolest technology from Day 1 of CES 2026\"\n",
    "[8]: https://www.aicas.com/press-release/ces-2026-perspective/?utm_source=chatgpt.com \"CES 2026: From Physical AI Hype to Execution in Automotive ...\"\n",
    "[9]: https://www.ft.com/content/3449e77c-721b-4fc9-8082-c584d8f74848?utm_source=chatgpt.com \"Physical AI: robotics are poised to revolutionise business\"\n",
    "[10]: https://nvidianews.nvidia.com/news/nvidia-launches-cosmos-world-foundation-model-platform-to-accelerate-physical-ai-development?utm_source=chatgpt.com \"NVIDIA Launches Cosmos World Foundation Model ...\"\n",
    "[11]: https://www.reuters.com/business/autos-transportation/arm-launches-physical-ai-division-expand-robotics-market-2026-01-07/?utm_source=chatgpt.com \"Arm launches 'Physical AI' unit, joining rush to robotics by tech and automakers\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a7d425",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8808225e",
   "metadata": {},
   "source": [
    "[![Advancing Physical AI with NVIDIA Cosmos World Foundation Model ...](https://tse4.mm.bing.net/th/id/OIP.gbM0pLfHUnbZhO2E0xkX-wHaEo?pid=Api)](https://developer.nvidia.com/blog/advancing-physical-ai-with-nvidia-cosmos-world-foundation-model-platform/?utm_source=chatgpt.com)\n",
    "\n",
    "\n",
    "\n",
    "## 2025 (Physical AI “개념/플랫폼”이 전면으로 올라온 해)\n",
    "\n",
    "* **Cosmos/월드모델 기반 개발·시뮬 중심 구도**(개발 패러다임 제시)\n",
    "* **CES 2025 키노트(Physical AI 메시지 확산의 상징 컷)**\n",
    "\n",
    "## 2026 (Physical AI가 “로봇/엣지/운영 체계”로 내려온 해)\n",
    "\n",
    "* **CES 현장 로봇 전시(로봇이 메인스트림 테마로 이동)**\n",
    "* **엣지 실행(예: Jetson T4000 계열) 강조 — 실시간/저지연 물리 AI의 상징**\n",
    "\n",
    "---\n",
    "\n",
    "[![Humanoid Robots on Factory Floor Revolutionize Manufacturing with AI ...](https://tse1.mm.bing.net/th/id/OIP.Ktd8k-gS2lf_tNZgiROrcAHaEK?pid=Api)](https://www.tropicalhainan.com/humanoid-robots-on-factory-floor-revolutionize-manufacturing-with-ai-powered-collaboration/?utm_source=chatgpt.com)\n",
    "\n",
    "## 2027 (전망 이미지: “현장 투입/다중 로봇 협업”이 표준이 되는 방향)\n",
    "\n",
    "**CES 2027은 아직 열리지 않은 시점이므로, 아래 이미지는 “예상 전개(공장/물류 현장 다중 로봇 협업)”을 설명하기 위한 *대표 예시 이미지*입니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4dd37e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
