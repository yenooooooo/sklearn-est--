{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "674bc645",
   "metadata": {},
   "source": [
    "## í˜„ì¬ ì‹¤ë ¥ìœ¼ë¡œëŠ” í˜¼ìì„œ ë§Œë“¤ìˆ˜ê°€ ì—†ì–´ AIí”„ë¡¬í”„íŠ¸ë¥¼ ì´ìš©í•´ì„œ í•˜ë‚˜í•˜ë‚˜ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e82d438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### ğŸš¢ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ì ì˜ˆì¸¡ ëª¨ë¸ë§ í”„ë¡œì íŠ¸\n",
    "\n",
    "# 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (Environment Setup & Data Loading)\n",
    "\n",
    "# 2. ë°ì´í„° íƒìƒ‰ (Exploratory Data Analysis, EDA)\n",
    "\n",
    "# 3. ë°ì´í„° ì „ì²˜ë¦¬ (Data Preprocessing) \n",
    "\n",
    "# 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (Feature Engineering)\n",
    "\n",
    "# 5. ëª¨ë¸ë§ ë° í•™ìŠµ (Modeling & Training)\n",
    "\n",
    "# 6. ëª¨ë¸ í‰ê°€ ë° íŠœë‹ (Evaluation & Tuning)\n",
    "\n",
    "# 7. ìµœì¢… ì˜ˆì¸¡ ë° ì œì¶œ (Prediction & Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2f915d",
   "metadata": {},
   "source": [
    "### 1.í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ (Environment Setup & Data Loading)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d62d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ì‹œê°í™” ê·¸ë˜í”„ê°€ ë…¸íŠ¸ë¶ ì•ˆì— ë‚˜íƒ€ë‚˜ë„ë¡ ì„¤ì •\n",
    "%matplotlib inline\n",
    "# ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì •\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# ë°ì´í„° ê²½ë¡œ ì„¤ì • (í˜„ì¬ ë…¸íŠ¸ë¶ ìœ„ì¹˜ì˜ ìƒìœ„ í´ë”(../)ì— ìˆëŠ” data í´ë” ì ‘ê·¼)\n",
    "train_path = '../data/titanic/train.csv'\n",
    "test_path = '../data/titanic/test.csv'\n",
    "\n",
    "# íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "if os.path.exists(train_path):\n",
    "    print(f\"íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤: {train_path}\")\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "    print(\"ë°ì´í„° ë¡œë“œ ì„±ê³µ!\")\n",
    "    \n",
    "    # ë°ì´í„°ì˜ ì²˜ìŒ 5ì¤„ í™•ì¸\n",
    "    display(train_df.head())\n",
    "else:\n",
    "    print(f\"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”: {train_path}\")\n",
    "    print(f\"í˜„ì¬ ì‘ì—… ê²½ë¡œ: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb55d00",
   "metadata": {},
   "source": [
    "### 2.ë°ì´í„° íƒìƒ‰ (Exploratory Data Analysis, EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d52bec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì„¤ì • (ì‹œê°í™”ë¥¼ ìœ„í•´)\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. ë°ì´í„° ì •ë³´ í™•ì¸ (í–‰ ê°œìˆ˜, ì»¬ëŸ¼ íƒ€ì…, ê²°ì¸¡ì¹˜ ì¡´ì¬ ì—¬ë¶€ ë“±)\n",
    "print(\"### 1. ë°ì´í„° ì •ë³´ (Info) ###\")\n",
    "train_df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. ê¸°ìˆ  í†µê³„ëŸ‰ í™•ì¸ (í‰ê· , í‘œì¤€í¸ì°¨, 4ë¶„ìœ„ìˆ˜ ë“± - ìˆ˜ì¹˜í˜• ë°ì´í„°)\n",
    "print(\"### 2. ê¸°ìˆ  í†µê³„ëŸ‰ (Describe) ###\")\n",
    "display(train_df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 3. ê²°ì¸¡ì¹˜ ê°œìˆ˜ í™•ì¸\n",
    "print(\"### 3. ê²°ì¸¡ì¹˜ ê°œìˆ˜ (Null Count) ###\")\n",
    "print(train_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658064af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. íƒ€ê²Ÿ ë³€ìˆ˜ (Survived) ë¶„í¬ í™•ì¸\n",
    "f, ax = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# íŒŒì´ ì°¨íŠ¸ (ìƒì¡´ ë¹„ìœ¨)\n",
    "train_df['Survived'].value_counts().plot.pie(explode=[0, 0.1], autopct='%1.1f%%', ax=ax[0], shadow=True)\n",
    "ax[0].set_title('Survived')\n",
    "ax[0].set_ylabel('')\n",
    "\n",
    "# ì¹´ìš´íŠ¸ í”Œë¡¯ (ìƒì¡´ì ìˆ˜)\n",
    "sns.countplot(x='Survived', data=train_df, ax=ax[1])\n",
    "ax[1].set_title('Survived')\n",
    "plt.show()\n",
    "\n",
    "# 2. ì„±ë³„(Sex)ì— ë”°ë¥¸ ìƒì¡´ìœ¨\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='Sex', y='Survived', data=train_df)\n",
    "plt.title('Survival Rate by Sex')\n",
    "plt.show()\n",
    "\n",
    "# 3. ê°ì‹¤ ë“±ê¸‰(Pclass)ì— ë”°ë¥¸ ìƒì¡´ìœ¨\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='Pclass', y='Survived', data=train_df)\n",
    "plt.title('Survival Rate by Pclass')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ee6a08",
   "metadata": {},
   "source": [
    "### 3. ë°ì´í„° ì „ì²˜ë¦¬ (Data Preprocessing) -- **ì¤‘ìš”!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9d03fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. ë°ì´í„° ì „ì²˜ë¦¬ (Data Preprocessing)\n",
    "\n",
    "# 1. ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (Missing Values)\n",
    "# Age(ë‚˜ì´): ì¤‘ê°„ê°’(median)ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "train_df['Age'] = train_df['Age'].fillna(train_df['Age'].median())\n",
    "test_df['Age'] = test_df['Age'].fillna(test_df['Age'].median())\n",
    "\n",
    "# Embarked(íƒ‘ìŠ¹ í•­êµ¬): ìµœë¹ˆê°’(ê°€ì¥ ë§ì´ ë‚˜ì˜¨ ê°’)ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "embarked_mode = train_df['Embarked'].mode()[0]\n",
    "train_df['Embarked'] = train_df['Embarked'].fillna(embarked_mode)\n",
    "test_df['Embarked'] = test_df['Embarked'].fillna(embarked_mode)\n",
    "\n",
    "# Fare(ìš´ì„): í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ê²°ì¸¡ì¹˜ê°€ 1ê°œ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¤‘ê°„ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "test_df['Fare'] = test_df['Fare'].fillna(test_df['Fare'].median())\n",
    "\n",
    "# Cabin(ê°ì‹¤ ë²ˆí˜¸): ê²°ì¸¡ì¹˜ê°€ ë„ˆë¬´ ë§ìœ¼ë¯€ë¡œ(70% ì´ìƒ) ì»¬ëŸ¼ ìì²´ë¥¼ ì‚­ì œ\n",
    "train_df = train_df.drop(['Cabin'], axis=1)\n",
    "test_df = test_df.drop(['Cabin'], axis=1)\n",
    "\n",
    "# 2. ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±° (Unnecessary Columns)\n",
    "# Name(ì´ë¦„), Ticket(í‹°ì¼“ ë²ˆí˜¸)ëŠ” ë‹¨ìˆœ ì²˜ë¦¬ë¡œëŠ” ëª¨ë¸ì— ë„ì›€ì´ ì ìœ¼ë¯€ë¡œ ì‚­ì œ\n",
    "# (PassengerIdëŠ” í•™ìŠµì— í•„ìš” ì—†ì§€ë§Œ ë‚˜ì¤‘ì— í™•ì¸ì„ ìœ„í•´ trainì—ì„œë§Œ ì œê±°í•˜ê±°ë‚˜ ì¸ë±ìŠ¤ë¡œ í™œìš© ê°€ëŠ¥)\n",
    "# ì—¬ê¸°ì„œëŠ” í•™ìŠµìš© ë°ì´í„°ì…‹ ì •ë¦¬ê°€ ëª©ì ì´ë¯€ë¡œ Name, Ticket ë¨¼ì € ì œê±°\n",
    "drop_cols = ['Name', 'Ticket']\n",
    "train_df = train_df.drop(drop_cols, axis=1)\n",
    "test_df = test_df.drop(drop_cols, axis=1)\n",
    "\n",
    "# 3. ë²”ì£¼í˜• ë°ì´í„° ì¸ì½”ë”© (Categorical Encoding)\n",
    "# ë¬¸ìì—´(String)ì„ ìˆ«ì(Number)ë¡œ ë³€ê²½í•´ì•¼ ëª¨ë¸ì´ ì´í•´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "# Sex(ì„±ë³„): male -> 0, female -> 1\n",
    "sex_mapping = {'male': 0, 'female': 1}\n",
    "train_df['Sex'] = train_df['Sex'].map(sex_mapping)\n",
    "test_df['Sex'] = test_df['Sex'].map(sex_mapping)\n",
    "\n",
    "# Embarked(í•­êµ¬): S -> 0, C -> 1, Q -> 2\n",
    "embarked_mapping = {'S': 0, 'C': 1, 'Q': 2}\n",
    "train_df['Embarked'] = train_df['Embarked'].map(embarked_mapping)\n",
    "test_df['Embarked'] = test_df['Embarked'].map(embarked_mapping)\n",
    "\n",
    "# ì „ì²˜ë¦¬ ê²°ê³¼ í™•ì¸\n",
    "print(\"ì „ì²˜ë¦¬ í›„ ë°ì´í„° ì •ë³´:\")\n",
    "train_df.info()\n",
    "print(\"\\nì „ì²˜ë¦¬ í›„ ìƒìœ„ 5ê°œ ë°ì´í„°:\")\n",
    "display(train_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d4b012",
   "metadata": {},
   "source": [
    "### 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (Feature Engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc90480",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 4. í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ (Feature Engineering)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. ìƒˆë¡œìš´ í”¼ì²˜ ìƒì„±: ê°€ì¡± ìˆ˜ (FamilySize)\n",
    "# í˜•ì œìë§¤/ë°°ìš°ì(SibSp) + ë¶€ëª¨/ìë…€(Parch) + ë‚˜ ìì‹ (1)\n",
    "train_df['FamilySize'] = train_df['SibSp'] + train_df['Parch'] + 1\n",
    "test_df['FamilySize'] = test_df['SibSp'] + test_df['Parch'] + 1\n",
    "\n",
    "# 2. ìƒˆë¡œìš´ í”¼ì²˜ ìƒì„±: í˜¼ì íƒ‘ìŠ¹ ì—¬ë¶€ (IsAlone)\n",
    "# ê°€ì¡± ìˆ˜ê°€ 1ëª…ì´ë©´ í˜¼ì íƒ‘ìŠ¹í•œ ê²ƒ (1: True, 0: False)\n",
    "train_df['IsAlone'] = 0\n",
    "train_df.loc[train_df['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "test_df['IsAlone'] = 0\n",
    "test_df.loc[test_df['FamilySize'] == 1, 'IsAlone'] = 1\n",
    "\n",
    "# 3. ë°ì´í„° ìŠ¤ì¼€ì¼ë§ (Scaling)\n",
    "# ë‚˜ì´(Age)ì™€ ìš”ê¸ˆ(Fare)ì˜ ë‹¨ìœ„ ì°¨ì´ê°€ í¬ë¯€ë¡œ, í‰ê·  0, í‘œì¤€í¸ì°¨ 1ì´ ë˜ë„ë¡ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "# (íŠ¸ë¦¬ ëª¨ë¸ì—ì„œëŠ” í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ, ë¡œì§€ìŠ¤í‹± íšŒê·€ ë“± ë‹¤ë¥¸ ëª¨ë¸ì„ ìœ„í•´ ê¶Œì¥ë©ë‹ˆë‹¤.)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scale_cols = ['Age', 'Fare']\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°(train_df)ì˜ í†µê³„ëŸ‰ì„ ê¸°ì¤€ìœ¼ë¡œ ìŠ¤ì¼€ì¼ë§ í•™ìŠµ(fit)\n",
    "scaler.fit(train_df[scale_cols])\n",
    "\n",
    "# í•™ìŠµëœ ê¸°ì¤€ìœ¼ë¡œ ë°ì´í„° ë³€í™˜(transform)\n",
    "train_df[scale_cols] = scaler.transform(train_df[scale_cols])\n",
    "test_df[scale_cols] = scaler.transform(test_df[scale_cols])\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸\n",
    "print(\"í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì™„ë£Œ!\")\n",
    "print(\"\\nìƒì„±ëœ íŒŒìƒ ë³€ìˆ˜ ë° ìŠ¤ì¼€ì¼ë§ ê²°ê³¼ í™•ì¸:\")\n",
    "display(train_df[['Age', 'Fare', 'FamilySize', 'IsAlone']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9e10f",
   "metadata": {},
   "source": [
    "### 5. ëª¨ë¸ë§ ë° í•™ìŠµ (Modeling & Training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597529e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 5. ëª¨ë¸ë§ ë° í•™ìŠµ (Modeling & Training)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. í•™ìŠµ ë°ì´í„°ì™€ ì •ë‹µ(Label) ë¶„ë¦¬\n",
    "# PassengerIdëŠ” ì˜ˆì¸¡ì— ì˜ë¯¸ê°€ ì—†ìœ¼ë¯€ë¡œ ì œì™¸, SurvivedëŠ” ì •ë‹µì´ë¯€ë¡œ ë¶„ë¦¬\n",
    "X = train_df.drop(['PassengerId', 'Survived'], axis=1)\n",
    "y = train_df['Survived']\n",
    "\n",
    "# 2. í•™ìŠµìš©(Train)ê³¼ ê²€ì¦ìš©(Validation) ë°ì´í„° ë¶„ë¦¬\n",
    "# ì „ì²´ ë°ì´í„°ì˜ 20%ë¥¼ ê²€ì¦ìš©ìœ¼ë¡œ ë”°ë¡œ ë–¼ì–´ë†“ìŠµë‹ˆë‹¤.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"í•™ìŠµ ë°ì´í„° í¬ê¸°: {X_train.shape}\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„° í¬ê¸°: {X_val.shape}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 3. ëª¨ë¸ ìƒì„± ë° í•™ìŠµ, í‰ê°€\n",
    "\n",
    "# (1) ì˜ì‚¬ê²°ì •ë‚˜ë¬´ (Decision Tree)\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train, y_train)\n",
    "dt_pred = dt_clf.predict(X_val)\n",
    "print(f\"Decision Tree ì •í™•ë„: {accuracy_score(y_val, dt_pred):.4f}\")\n",
    "\n",
    "# (2) ëœë¤ í¬ë ˆìŠ¤íŠ¸ (Random Forest)\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_pred = rf_clf.predict(X_val)\n",
    "print(f\"Random Forest ì •í™•ë„: {accuracy_score(y_val, rf_pred):.4f}\")\n",
    "\n",
    "# (3) ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)\n",
    "lr_clf = LogisticRegression(random_state=42)\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_pred = lr_clf.predict(X_val)\n",
    "print(f\"Logistic Regression ì •í™•ë„: {accuracy_score(y_val, lr_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f3081",
   "metadata": {},
   "source": [
    "### 6.ëª¨ë¸ í‰ê°€ ë° íŠœë‹ (Evaluation & Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca1552",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 6. ëª¨ë¸ í‰ê°€ ë° íŠœë‹ (Evaluation & Tuning)\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "# 1. êµì°¨ ê²€ì¦ (Cross Validation)\n",
    "# ë°ì´í„°ë¥¼ 5ë“±ë¶„í•´ì„œ ë²ˆê°ˆì•„ê°€ë©° ê²€ì¦í•˜ì—¬, ê²°ê³¼ê°€ ìš°ì—°íˆ ì˜ ë‚˜ì˜¨ ê²ƒì´ ì•„ë‹˜ì„ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "# (ì´ì „ ë‹¨ê³„ì—ì„œ ë§Œë“  rf_clf ëª¨ë¸ ì‚¬ìš©)\n",
    "scores = cross_val_score(rf_clf, X_train, y_train, cv=5)\n",
    "\n",
    "print(\"### êµì°¨ ê²€ì¦ ê²°ê³¼ ###\")\n",
    "print(f\"ê°œë³„ ì •í™•ë„: {scores}\")\n",
    "print(f\"í‰ê·  ì •í™•ë„: {np.mean(scores):.4f}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "# 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ (GridSearchCV)\n",
    "# Random Forestì˜ ì˜µì…˜(ë‚˜ë¬´ ê°œìˆ˜, ê¹Šì´ ë“±)ì„ ë‹¤ì–‘í•˜ê²Œ ì¡°í•©í•´ì„œ ê°€ì¥ ì¢‹ì€ ì„±ëŠ¥ì„ ì°¾ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200],     # ë‚˜ë¬´ì˜ ê°œìˆ˜\n",
    "    'max_depth': [None, 10, 20],        # ë‚˜ë¬´ì˜ ìµœëŒ€ ê¹Šì´ (ë„ˆë¬´ ê¹Šìœ¼ë©´ ê³¼ì í•© ê°€ëŠ¥ì„±)\n",
    "    'min_samples_leaf': [1, 2, 4],      # ë¦¬í”„ ë…¸ë“œì— ìˆì–´ì•¼ í•˜ëŠ” ìµœì†Œ ìƒ˜í”Œ ìˆ˜\n",
    "    'min_samples_split': [2, 5, 10]     # ë…¸ë“œ ë¶„í• ì„ ìœ„í•œ ìµœì†Œ ìƒ˜í”Œ ìˆ˜\n",
    "}\n",
    "\n",
    "# n_jobs=-1ì€ ì»´í“¨í„°ì˜ ëª¨ë“  ì„±ëŠ¥ì„ ì¨ì„œ ë¹¨ë¦¬ ê³„ì‚°í•˜ë¼ëŠ” ëœ»ì…ë‹ˆë‹¤.\n",
    "grid_rf = GridSearchCV(RandomForestClassifier(random_state=42), \n",
    "                       param_grid=params, \n",
    "                       cv=5, \n",
    "                       n_jobs=-1)\n",
    "\n",
    "grid_rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\n### íŠœë‹ ê²°ê³¼ ###\")\n",
    "print(f\"ìµœì ì˜ íŒŒë¼ë¯¸í„°: {grid_rf.best_params_}\")\n",
    "print(f\"ìµœê³  ì •í™•ë„ (Best Score): {grid_rf.best_score_:.4f}\")\n",
    "\n",
    "# 3. ìµœì ì˜ ëª¨ë¸ë¡œ ì—…ë°ì´íŠ¸\n",
    "# íŠœë‹ëœ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ì„ best_model ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "best_model = grid_rf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d458b62f",
   "metadata": {},
   "source": [
    "### 7. ìµœì¢… ì˜ˆì¸¡ ë° ì œì¶œ (Prediction & Submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80feb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost ëª¨ë¸ ìƒì„± ë° í•™ìŠµ\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# (ì£¼ì˜) ë§Œì•½ X_train, y_trainì´ ì •ì˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´ train_test_split ì½”ë“œë„ ë‹¤ì‹œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "# ì•ˆì „í•˜ê²Œ ë‹¤ì‹œ í•œ ë²ˆ ë°ì´í„°ë¥¼ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "X = train_df.drop(['PassengerId', 'Survived'], axis=1)\n",
    "y = train_df['Survived']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ\n",
    "xgb_clf = XGBClassifier(n_estimators=100, learning_rate=0.05, max_depth=5, random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"XGBoost ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e50227d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì œì¶œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived\n",
       "0          892         0\n",
       "1          893         1\n",
       "2          894         0\n",
       "3          895         0\n",
       "4          896         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'submission.csv' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "## 7. ìµœì¢… ì˜ˆì¸¡ ë° ì œì¶œ (Prediction & Submission)\n",
    "\n",
    "# 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„\n",
    "# í•™ìŠµí•  ë•Œ PassengerIdëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì•˜ìœ¼ë¯€ë¡œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œë„ ì œì™¸í•´ì•¼ ëª¨ë¸ì´ í—·ê°ˆë¦¬ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "X_test_final = test_df.drop(['PassengerId'], axis=1)\n",
    "\n",
    "# 2. ì˜ˆì¸¡ ìˆ˜í–‰ (XGBoost ëª¨ë¸ ì‚¬ìš©)\n",
    "final_pred = xgb_clf.predict(X_test_final)\n",
    "\n",
    "# (ë§Œì•½ Random Forest íŠœë‹ ëª¨ë¸ì„ ì“°ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ ì£¼ì„ì„ í’€ê³  ì‹¤í–‰í•˜ì„¸ìš”)\n",
    "# final_pred = best_model.predict(X_test_final)\n",
    "\n",
    "# 3. ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "# PassengerIdì™€ ì˜ˆì¸¡ëœ Survived ê°’ì„ í•©ì³ì„œ ë°ì´í„°í”„ë ˆì„ì„ ë§Œë“­ë‹ˆë‹¤.\n",
    "submission = pd.DataFrame({\n",
    "    \"PassengerId\": test_df[\"PassengerId\"],\n",
    "    \"Survived\": final_pred\n",
    "})\n",
    "\n",
    "# ê²°ê³¼ í™•ì¸ (ìƒìœ„ 5ê°œ)\n",
    "print(\"ì œì¶œ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "display(submission.head())\n",
    "\n",
    "# 4. CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "# index=Falseë¥¼ í•´ì•¼ ë¶ˆí•„ìš”í•œ ì¸ë±ìŠ¤ ë²ˆí˜¸ê°€ ì €ì¥ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n",
    "submission.to_csv('titanic_submission.csv', index=False)\n",
    "\n",
    "print(\"\\n'submission.csv' íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
